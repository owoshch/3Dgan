{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Training for GAN\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "## setting seed ###\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "import random\n",
    "random.seed(1)\n",
    "os.environ['PYTHONHASHSEED'] = '0' \n",
    "##################\n",
    "\n",
    "from collections import defaultdict\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import keras\n",
    "import argparse\n",
    "import sys\n",
    "import h5py \n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import analysis.utils.GANutils as gan\n",
    "if os.environ.get('HOSTNAME') == 'tlab-gpu-oldeeptector.cern.ch': # Here a check for host can be used to set defaults accordingly\n",
    "    tlab = True\n",
    "else:\n",
    "    tlab= False\n",
    "    \n",
    "try:\n",
    "    import setGPU #if Caltech\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from memory_profiler import profile # used for memory profiling\n",
    "import keras.backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adadelta, Adam, RMSprop\n",
    "from keras.utils.generic_utils import Progbar\n",
    "config = tf.ConfigProto(log_device_placement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='3D GAN Params' )\n",
    "    parser.add_argument('--nbepochs', action='store', type=int, default=60, help='Number of epochs to train for.')\n",
    "    parser.add_argument('--batchsize', action='store', type=int, default=64, help='batch size per update')\n",
    "    parser.add_argument('--latentsize', action='store', type=int, default=256, help='size of random N(0, 1) latent space to sample')\n",
    "    parser.add_argument('--datapath', action='store', type=str, default='/eos/user/g/gkhattak/VarAngleData/*Measured3ThetaEscan/*.h5', help='HDF5 files to train from.')\n",
    "    parser.add_argument('--dformat', action='store', type=str, default='channels_last')\n",
    "    parser.add_argument('--nEvents', action='store', type=int, default=200000, help='Maximum Number of events used for Training')\n",
    "    parser.add_argument('--verbose', action='store_true', help='Whether or not to use a progress bar')\n",
    "    parser.add_argument('--xscale', action='store', type=int, default=1, help='Multiplication factor for ecal deposition')\n",
    "    parser.add_argument('--xpower', action='store', type=float, default=0.85, help='pre processing of cell energies by raising to a power')\n",
    "    parser.add_argument('--yscale', action='store', type=int, default=100, help='Division Factor for Primary Energy.')\n",
    "    parser.add_argument('--ascale', action='store', type=int, default=1, help='Multiplication factor for angle input')\n",
    "    parser.add_argument('--analyse', action='store', default=False, help='Whether or not to perform analysis')\n",
    "    parser.add_argument('--gen_weight', action='store', type=float, default=3, help='loss weight for generation real/fake loss')\n",
    "    parser.add_argument('--aux_weight', action='store', type=float, default=0.1, help='loss weight for auxilliary energy regression loss')\n",
    "    parser.add_argument('--ang_weight', action='store', type=float, default=25, help='loss weight for angle loss')\n",
    "    parser.add_argument('--ecal_weight', action='store', type=float, default=0.1, help='loss weight for ecal sum loss')\n",
    "    parser.add_argument('--hist_weight', action='store', type=float, default=0.1, help='loss weight for additional bin count loss')\n",
    "    parser.add_argument('--thresh', action='store', type=int, default=0., help='Threshold for cell energies')\n",
    "    parser.add_argument('--angtype', action='store', type=str, default='mtheta', help='Angle to use for Training. It can be theta, mtheta or eta')\n",
    "    parser.add_argument('--particle', action='store', type=str, default='Ele', help='Type of particle')\n",
    "    parser.add_argument('--lr', action='store', type=float, default=0.0008, help='Learning rate')\n",
    "    parser.add_argument('--name', action='store', type=str, default='training', help='Unique identifier can be set for each training')\n",
    "    return parser\n",
    "\n",
    "# A histogram fucntion that counts cells in different bins\n",
    "def hist_count(x, p=1.0, daxis=(1, 2, 3)):\n",
    "    limits=np.array([0.05, 0.03, 0.02, 0.0125, 0.008, 0.003]) # bin boundaries used\n",
    "    limits= np.power(limits, p)\n",
    "    bin1 = np.sum(np.where(x>(limits[0]) , 1, 0), axis=daxis)\n",
    "    bin2 = np.sum(np.where((x<(limits[0])) & (x>(limits[1])), 1, 0), axis=daxis)\n",
    "    bin3 = np.sum(np.where((x<(limits[1])) & (x>(limits[2])), 1, 0), axis=daxis)\n",
    "    bin4 = np.sum(np.where((x<(limits[2])) & (x>(limits[3])), 1, 0), axis=daxis)\n",
    "    bin5 = np.sum(np.where((x<(limits[3])) & (x>(limits[4])), 1, 0), axis=daxis)\n",
    "    bin6 = np.sum(np.where((x<(limits[4])) & (x>(limits[5])), 1, 0), axis=daxis)\n",
    "    bin7 = np.sum(np.where((x<(limits[5])) & (x>0.), 1, 0), axis=daxis)\n",
    "    bin8 = np.sum(np.where(x==0, 1, 0), axis=daxis)\n",
    "    bins = np.concatenate([bin1, bin2, bin3, bin4, bin5, bin6, bin7, bin8], axis=1)\n",
    "    bins[np.where(bins==0)]=1 # so that an empty bin will be assigned a count of 1 to avoid unstability\n",
    "    return bins\n",
    "\n",
    "#get data for training\n",
    "def GetDataAngle(datafile, xscale =1, xpower=1, yscale = 100, angscale=1, angtype='theta', thresh=1e-4, daxis=4):\n",
    "    print ('Loading Data from .....', datafile)\n",
    "    f=h5py.File(datafile,'r')\n",
    "    ang = np.array(f.get(angtype))\n",
    "    X=np.array(f.get('ECAL'))* xscale\n",
    "    Y=np.array(f.get('energy'))/yscale\n",
    "    X[X < thresh] = 0\n",
    "    X = X.astype(np.float32)\n",
    "    Y = Y.astype(np.float32)\n",
    "    ang = ang.astype(np.float32)\n",
    "    ecal = np.sum(X, axis=(1, 2, 3))\n",
    "    X = np.expand_dims(X, axis=daxis)\n",
    "    if xpower !=1.:\n",
    "        X = np.power(X, xpower)\n",
    "    return X, Y, ang, ecal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AngleArch3dGAN import generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(analyse=False, ang_weight=25, angtype='mtheta', ascale=1, aux_weight=0.1, batchsize=64, datapath='../../3dgan_files/data/LCD/EleMeasuredThetaEscan/*.h5', dformat='channels_last', ecal_weight=0.1, gen_weight=3, hist_weight=0.1, latentsize=256, lr=0.0008, nEvents=200000, name='training', nbepochs=60, particle='Ele', thresh=0.0, verbose=False, xpower=0.85, xscale=1, yscale=100)\n"
     ]
    }
   ],
   "source": [
    "parser = get_parser()\n",
    "#params = parser.parse_args()\n",
    "params = parser.parse_args(\"--datapath=../../3dgan_files/data/LCD/EleMeasuredThetaEscan/*.h5\".split())\n",
    "nb_epochs = params.nbepochs #Total Epochs\n",
    "batch_size = params.batchsize #batch size\n",
    "latent_size = params.latentsize #latent vector size\n",
    "verbose = params.verbose\n",
    "datapath = params.datapath# Data path\n",
    "nEvents = params.nEvents# maximum number of events used in training\n",
    "ascale = params.ascale # angle scale\n",
    "yscale = params.yscale # scaling energy\n",
    "weightdir = 'weights/3dgan_weights_' + params.name\n",
    "pklfile = 'results/3dgan_history_' + params.name + '.pkl'# loss history\n",
    "resultfile = 'results/3dgan_analysis' + params.name + '.pkl'# optimization metric history\n",
    "xscale = params.xscale\n",
    "xpower = params.xpower\n",
    "analyse=params.analyse # if analysing\n",
    "loss_weights=[params.gen_weight, params.aux_weight, params.ang_weight, params.ecal_weight, params.hist_weight]\n",
    "dformat=params.dformat\n",
    "thresh = params.thresh # threshold for data\n",
    "angtype = params.angtype\n",
    "particle = params.particle\n",
    "lr = params.lr\n",
    "energies = [110, 150, 190] # bins used in short analysis\n",
    "if tlab:\n",
    "    #datapath = '/gkhattak/data/*Measured3ThetaEscan/*.h5'\n",
    "    weightdir = '/gkhattak/weights/3dgan_weights_' + params.name \n",
    "    pklfile = '/gkhattak/results/3dgan_history_' +  params.name +'.pkl'\n",
    "    resultfile = '/gkhattak/results/3dgan_analysis_' +  params.name +'.pkl'\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 51, 51, 25, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 51, 51, 25, 16)    2896      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 51, 51, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 51, 51, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 51, 51, 27, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 47, 46, 22, 8)     23048     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 47, 46, 22, 8)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 47, 46, 22, 8)     32        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 47, 46, 22, 8)     0         \n",
      "_________________________________________________________________\n",
      "zero_padding3d_2 (ZeroPaddin (None, 47, 46, 24, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 43, 41, 19, 8)     11528     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 43, 41, 19, 8)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 43, 41, 19, 8)     32        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 43, 41, 19, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 39, 36, 14, 8)     11528     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 39, 36, 14, 8)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 39, 36, 14, 8)     32        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 39, 36, 14, 8)     0         \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 19, 18, 7, 8)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 19152)             0         \n",
      "=================================================================\n",
      "Total params: 49,096\n",
      "Trainable params: 49,048\n",
      "Non-trainable params: 48\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 51, 51, 25, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 19152)        49096       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 51, 51, 25, 1 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "generation (Dense)              (None, 1)            19153       model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "auxiliary (Dense)               (None, 1)            19153       model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 8, 1)         0           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 87,402\n",
      "Trainable params: 87,354\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 5184)              1332288   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 9, 9, 8, 8)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3 (None, 54, 54, 48, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 49, 49, 41, 8)     18440     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 49, 49, 41, 8)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 49, 49, 41, 8)     32        \n",
      "_________________________________________________________________\n",
      "zero_padding3d_3 (ZeroPaddin (None, 53, 53, 43, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 50, 50, 38, 6)     4614      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 50, 38, 6)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50, 50, 38, 6)     24        \n",
      "_________________________________________________________________\n",
      "zero_padding3d_4 (ZeroPaddin (None, 54, 54, 40, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 51, 51, 35, 6)     3462      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 51, 51, 35, 6)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 51, 51, 35, 6)     24        \n",
      "_________________________________________________________________\n",
      "zero_padding3d_5 (ZeroPaddin (None, 55, 55, 37, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 52, 52, 32, 6)     3462      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 52, 52, 32, 6)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 52, 52, 32, 6)     24        \n",
      "_________________________________________________________________\n",
      "zero_padding3d_6 (ZeroPaddin (None, 54, 54, 32, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 52, 52, 28, 6)     1626      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 52, 52, 28, 6)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 52, 52, 28, 6)     24        \n",
      "_________________________________________________________________\n",
      "zero_padding3d_7 (ZeroPaddin (None, 54, 54, 28, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 52, 52, 26, 6)     978       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 52, 52, 26, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 51, 51, 25, 1)     49        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 51, 51, 25, 1)     0         \n",
      "=================================================================\n",
      "Total params: 1,365,047\n",
      "Trainable params: 1,364,983\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 51, 51, 25, 1)     1365047   \n",
      "=================================================================\n",
      "Total params: 1,365,047\n",
      "Trainable params: 1,364,983\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owoshch/Documents/CERN/binder/3Dgan/keras/AngleArch3dGAN.py:196: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  Model(input=[latent], output=[fake_image]).summary()\n",
      "/Users/owoshch/Documents/CERN/binder/3Dgan/keras/AngleArch3dGAN.py:197: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  return Model(input=[latent], output=[fake_image])\n"
     ]
    }
   ],
   "source": [
    "# Building discriminator and generator\n",
    "gan.safe_mkdir(weightdir)\n",
    "d=discriminator(xpower, dformat=dformat)\n",
    "g=generator(latent_size, dformat=dformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf",
   "language": "python",
   "name": "keras_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
